{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ef0595-236a-4689-afd8-76a5cf38bc31",
   "metadata": {},
   "source": [
    "# Linear Systems : Matrices, Vectors, eigen systems\n",
    "In this module we will learn how to solve linear systems which are very common in engineering and applied physics.\n",
    "\n",
    "Applications are numerous: \n",
    "- Civil, chemical, electrical, mechanical, ..., engineering\n",
    "- In biology by using linear algebra to analyze huge data sets regarding protein folding. https://math.stackexchange.com/questions/571109/any-application-of-vector-spaces-in-biology-or-biotechnology\n",
    "- In genetics to model the evolution of genes.\n",
    "- Markov chains on industrial processes with applications of matrices and eigen systems. \n",
    "- Population dynamics. \n",
    "- Perception of colors. \n",
    "- Adjacency graphs: https://en.wikipedia.org/wiki/Adjacency_matrix , https://towardsdatascience.com/matrices-are-graphs-c9034f79cfd8\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a856d1-57e6-41db-8f4e-9f213d55a4ed",
   "metadata": {},
   "source": [
    "One particular common operation, the matrix multiplication, is still the subject of ongoing research:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://d2r55xnwy6nx47.cloudfront.net/uploads/2021/03/Matrix_multiplication_2880x1620_Lede.jpg\" alt=\"Image Description\" width=\"900\">\n",
    "    <figcaption>From: \"https://d2r55xnwy6nx47.cloudfront.net/uploads/2021/03/Matrix_multiplication_2880x1620_Lede.jpg\"</figcaption>\n",
    "</div>\n",
    "\n",
    "- https://www.quantamagazine.org/mathematicians-inch-closer-to-matrix-multiplication-goal-20210323/\n",
    "- https://www.quantamagazine.org/ai-reveals-new-possibilities-in-matrix-multiplication-20221123/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351fe873-1775-4044-b9e1-3ef6d0e7853d",
   "metadata": {},
   "source": [
    "Tips about matrix computing:\n",
    "- https://nhigham.com/2022/10/11/seven-sins-of-numerical-linear-algebra/\n",
    "- http://gregorygundersen.com/blog/2020/12/09/matrix-inversion/\n",
    "- https://gamemath.com/book/intro.html\n",
    "- https://docs.godotengine.org/en/stable/tutorials/math/vector_math.html\n",
    "- https://www.youtube.com/watch?v=fDAPJ7rvcUw\n",
    "\n",
    "Furthermore, for eigen values, please check \n",
    "https://www.youtube.com/watch?v=PFDu9oVAE-g&t=0s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aaca79-eebd-4e65-8edc-5d07c258788a",
   "metadata": {},
   "source": [
    "# Eigen c++\n",
    "Eigen is a C++ template library for linear algebra: matrices, vectors, numerical solvers, and related algorithms.\n",
    "- http://eigen.tuxfamily.org/index.php?title=Main_Page\n",
    "- http://eigen.tuxfamily.org/dox/GettingStarted.html\n",
    "\n",
    "Quick reference: https://eigen.tuxfamily.org/dox/group__QuickRefPage.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee1bd68-0a50-4dd0-a659-75c7d721ecf9",
   "metadata": {},
   "source": [
    "# Solving $Ax = b$\n",
    "\n",
    "This is one of the archetypical problems in numerical algebra. You migh try to implement it by hand, but it will probable be not efficient, stable, etc (Remember https://nhigham.com/2022/10/11/seven-sins-of-numerical-linear-algebra/). Better to use a numerical library to do the heavy task for you. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3211b37-152c-4bdf-a921-bfad057df90a",
   "metadata": {},
   "source": [
    "## QR decomposition\n",
    "\n",
    "In this example we are going to use eigen to solve the system using HouseHolder QR decomposition as done in http://eigen.tuxfamily.org/dox/group__TutorialLinearAlgebra.html . Please create a file with the following code, compile it and run it. You are supposed to have already installed eigen (the computer room and the binder machine both have it).\n",
    "\n",
    "```c++\n",
    "# include <iostream>\n",
    "# include <Eigen/Dense>\n",
    "\n",
    "int main()\n",
    "{\n",
    "   Eigen::Matrix3d A;\n",
    "   Eigen::Vector3d b;\n",
    "   //std::cout.precision(16);\n",
    "   //std::cout.setf(std::ios::scientific);\n",
    "   \n",
    "   A << 1,2,3,  4,5,6,  7,8,10;\n",
    "   b << 3, 3, 4;\n",
    "   std::cout << \"Here is the matrix A:\\n\" << A << std::endl;\n",
    "   std::cout << \"Here is the vector b:\\n\" << b << std::endl;\n",
    "   Eigen::Vector3d x = A.colPivHouseholderQr().solve(b);\n",
    "   std::cout << \"The solution is:\\n\" << x << std::endl;\n",
    "   std::cout << (A*x - b).norm() << \"\\n\";\n",
    "   return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0849ad1-382b-43fd-b746-fc1803a4173b",
   "metadata": {},
   "source": [
    "If the library is installed on system paths, just compile it as \n",
    "```bash\n",
    "g++ -std=c++17 qr.cpp -o qr.x\n",
    "```\n",
    "or compile it optimized as \n",
    "```bash\n",
    "g++ -std=c++17 -O3 qr.cpp -o qr.x\n",
    "```\n",
    "and then run it\n",
    "```bash\n",
    "./qr.x\n",
    "```\n",
    "What do you get? is the optimized code faster than the original one? why? why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134642fa-fd4b-4da8-b31e-61431652f3f1",
   "metadata": {},
   "source": [
    "## Installation and compilation tips\n",
    "Try the following:\n",
    "- Library installed at `/usr/include/eigen3` or `/usr/local/include/eigen3`: Then you need to tell the compiler where to find the headers\n",
    "  ```bash\n",
    "  g++ -std=c++17 -O3 -I /usr/include/eigen3 qr.cpp -o qr.x\n",
    "  ```\n",
    "  or, if you installed it on a specific path\n",
    "  ```bash\n",
    "  g++ -std=c++17 -O3 -I /path/to/installdir/ qr.cpp -o qr.x\n",
    "  ```\n",
    "- Install it : On systems like ubuntu, you could use\n",
    "  ```bash\n",
    "  sudo apt install libeigen3-dev\n",
    "  ```\n",
    "  In collab,\n",
    "  ```bash\n",
    "  apt install libeigen3-dev\n",
    "  ```\n",
    "  In the course provisioned binder, you do not need to install, it is already installed.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96564f9a-a0e7-4cb6-a828-e7bb78c191d0",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "How to know that the solution is actuallya. solution of the original problem? design a criteria ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac557db-c33a-4a58-afdf-f78e32ba359a",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Now create a random matrix and vector, of arbitrary size `N`, and measure the time to compute the solution as a function of `N`. Use `Eigen::MatrixXd A = Eigen::MatrixXd::Random(N, N);` and `std::chrono`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7489d2f9-dc9c-4ef5-8eb7-2ef3bdb1a3da",
   "metadata": {},
   "source": [
    "## LU decomposition\n",
    "THe LU decomposition os another tool we can use to solve the system (advantages? disadvantages?)\n",
    "\n",
    "Now implement the following solution and compare with the previous one? The only change you need is\n",
    "```c++\n",
    "Eigen::MatrixXd x = A.fullPivLu().solve(b)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0461ce0a-4e9e-435d-8a14-450f5313407e",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dc19fc3eab86bc06",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lu.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lu.cpp\n",
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005ac7e-0e5d-4f69-b1d3-ac7de57db4cd",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Solving simple system\n",
    "Solve the system\n",
    "\n",
    "<img src=\"fig/linear-example-01.png\" width=300>\n",
    "\n",
    "\n",
    "## Performance between QR and LU\n",
    "Compare the time between LU and QR decompositions on random matrices.\n",
    "\n",
    "## Solve simple system\n",
    "<img src=\"fig/linear-example-03.png\" width=600>\n",
    "\n",
    "## Simulating temperature\n",
    "- Temperature discretized <img src=\"fig/linear-example-04-T.png\" width=300>\n",
    "- System of equations <img src=\"fig/linear-example-04-T-B.png\" width=300>\n",
    "\n",
    "## Laplace equation in 2D\n",
    "When solving the laplace equation $\\nabla V = 0$ to compute the electrostatic potential on a planar region, you can discretize the derivatives on a grid   and then arrive to the following equation\n",
    "   \\begin{equation}\n",
    "   V_{i+1,j} + V_{i-1,j} + V_{i,j+1} + V_{i,j-1} - 4V_{i,j} = 0.0.\n",
    "   \\end{equation}\n",
    "   This can be written as a matrix problem. Solve the matrix problem for a\n",
    "   square plate of lenght $L$, with $N$ points on each side. The boundary\n",
    "   conditions, of Dirichlet type, are $V(x, 0) = 5\\sin(\\pi x/L)$, $V(x, L) =\n",
    "   V(0, y) = V(L, y) = 0.0$.\n",
    "## Vandermonde determinant\n",
    "Compute the determinant of the [[https://en.wikipedia.org/wiki/Vandermonde_matrix][Vandermonde matrix]] of size $N\\times N$.\n",
    "   Measure the time as a function of $N$.\n",
    "## Condition number\n",
    "Compute the condition number for an arbitrary matrix $A$. Apply it for the\n",
    "   Vandermonde matrix. The condition number is defined as $\\kappa(A)\n",
    "   = |A^{-1}| |A|$\n",
    "\n",
    "## Rotation matrix\n",
    "Define a rotation matrix in 2d by an angle $\\theta$. Apply it to a given\n",
    "   vector and check that it is actually rotated.\n",
    "\n",
    "## Coupled oscillators\n",
    "Imagine that you have two masses $m_1, m_2$, coupled through springs in the\n",
    "   form wall-spring-mass-spring-mass-spring-wall. All spring are linear with\n",
    "   constant $k$. Write the equations of motion, replace each solution with\n",
    "   $x_i(t) =  A_i e^{i\\omega t}$, and obtain a matrix representation to get the\n",
    "   amplitudes. Compute the eigen values and eigen-vectors. Those are the [[https://en.wikipedia.org/wiki/Normal_mode][normal\n",
    "   modes]] . Extend to n oscillators of the same mass.\n",
    "\n",
    "# Thick lens (Boas, 3.15.9)\n",
    "The next matrix is used when discussing a thick lens in air\n",
    "\\begin{equation}\n",
    "A = \n",
    "\\begin{pmatrix}\n",
    "1 & (n-1)/R_2\\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "1 & 0\\\\\n",
    "d/n & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "1 & -(n-1)/R_1\\\\\n",
    "0 & 1\n",
    "\\end{pmatrix},\n",
    "\\end{equation}\n",
    "where $d$ is the thickness of the lens, $n$ is the refraction index, and $R_1$ and $R_2$ are the curvature radius. Element $A_{12}$ is equal to $-1/f$, where $f$ is the focal distance. Evaluate $\\det A$ and $1/f$ as functions of $n \\in [1, 3]$.  \n",
    "\n",
    "## Products production\n",
    "<img src=\"fig/problem-05.png\" width=300>\n",
    "\n",
    "## Teaching distribution\n",
    "<img src=\"fig/problem-06.png\" width=300>\n",
    "\n",
    "## Payments\n",
    "<img src=\"fig/problem-08.png\" width=300>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56edd0cc-b372-4154-928f-e39d35ff60ed",
   "metadata": {},
   "source": [
    "# Eigen vectors and eigen values\n",
    "Eigen-values ($\\lambda$) and eigen-vectors ($\\vec v$) of a matrix $A$ fulfill the following equation\n",
    "\\begin{equation}\n",
    "A\\vec v = \\lambda \\vec v,\n",
    "\\end{equation}\n",
    "and are extensively use in physics, statistics, computational methods, etc (see https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors?useskin=vector). For example, they are use to compute (https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors?useskin=vector#Applications):\n",
    "- Eigen values of the Schroedinger equation\n",
    "    <div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/c/cf/HAtomOrbitals.png\" alt=\"Image Description\" width=\"200\">\n",
    "    <figcaption>From: \"https://upload.wikimedia.org/wikipedia/commons/c/cf/HAtomOrbitals.png\"</figcaption>\n",
    "</div>\n",
    "- Diagonalization basis for matrices: Given a matrix $A$, and the matrix $P$ whose column vectors are the eigenvectors of $A$, then one can apply a basis trnasformation, to move to the eigen-vector matrices, and obtain a diagonal matrix $D$ (whose elements are the eigen values of $A$), as \n",
    "    \\begin{equation}\n",
    "    D = P^{-1}AP\n",
    "    \\end{equation}\n",
    "    <div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/4/4e/Diagonalization_as_rotation.gif\" alt=\"Image Description\" width=\"300\">\n",
    "    <figcaption>From: \"https://upload.wikimedia.org/wikipedia/commons/4/4e/Diagonalization_as_rotation.gif\"</figcaption>\n",
    "</div>\n",
    "\n",
    "- Normal mode of oscillatory systems\n",
    "    <div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Mode_Shape_of_a_Tuning_Fork_at_Eigenfrequency_440.09_Hz.gif/440px-Mode_Shape_of_a_Tuning_Fork_at_Eigenfrequency_440.09_Hz.gif\" alt=\"Image Description\" width=\"300\">\n",
    "    <figcaption>From: \"https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Mode_Shape_of_a_Tuning_Fork_at_Eigenfrequency_440.09_Hz.gif/440px-Mode_Shape_of_a_Tuning_Fork_at_Eigenfrequency_440.09_Hz.gif\"</figcaption>\n",
    "</div>\n",
    "- Principal component analysis in data science\n",
    "    <div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/GaussianScatterPCA.png/440px-GaussianScatterPCA.png\" alt=\"Image Description\" width=\"300\">\n",
    "    <figcaption>From: \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/GaussianScatterPCA.png/440px-GaussianScatterPCA.png\"</figcaption>\n",
    "</div>\n",
    "- Image analysis\n",
    "    <div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/67/Eigenfaces.png\" alt=\"Image Description\" width=\"200\">\n",
    "    <figcaption>From: \"https://upload.wikimedia.org/wikipedia/commons/6/67/Eigenfaces.png\"</figcaption>\n",
    "</div>\n",
    "- Moment of inertia\n",
    "    <div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Triaxial_Ellipsoid.jpg/440px-Triaxial_Ellipsoid.jpg\" alt=\"Image Description\" width=\"300\">\n",
    "    <figcaption>From: \"https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Triaxial_Ellipsoid.jpg/440px-Triaxial_Ellipsoid.jpg\"</figcaption>\n",
    "</div>\n",
    "- Stress tensor principal axis\n",
    "    <div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Plastic_Protractor_Polarized_05375.jpg/440px-Plastic_Protractor_Polarized_05375.jpg\" alt=\"Image Description\" width=\"300\">\n",
    "    <figcaption>From: \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Plastic_Protractor_Polarized_05375.jpg/440px-Plastic_Protractor_Polarized_05375.jpg\"</figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad4209-e8ae-424a-973b-5e9342d96b89",
   "metadata": {},
   "source": [
    "## Solving a general eigen value problem with eigen c++\n",
    "Following the documentation of the general eigen solver,\n",
    "https://eigen.tuxfamily.org/dox/classEigen_1_1EigenSolver.html, we can use the\n",
    "example to show how it works:\n",
    "\n",
    "```c++\n",
    "#include <iostream>\n",
    "#include <string>\n",
    "#include <Eigen/Dense>\n",
    "#include <complex>\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "  const int N = std::stoi(argv[1]);\n",
    "\n",
    "  Eigen::MatrixXd A = Eigen::MatrixXd::Random(N,N);\n",
    "  std::cout << \"Here is a random matrix, A:\" << std::endl \n",
    "            << A << std::endl << std::endl;\n",
    "\n",
    "  Eigen::EigenSolver<Eigen::MatrixXd> es(A);\n",
    "  std::cout << \"The eigenvalues of A are:\" << std::endl \n",
    "            << es.eigenvalues() << std::endl;\n",
    "  std::cout << \"The matrix of eigenvectors, V, is:\" << std::endl \n",
    "            << es.eigenvectors() << std::endl << std::endl;\n",
    "\n",
    "  std::complex<double> lambda = es.eigenvalues()[0];\n",
    "  std::cout << \"Consider the first eigenvalue, lambda = \" << lambda << std::endl;\n",
    "  Eigen::VectorXcd v = es.eigenvectors().col(0);\n",
    "  std::cout << \"If v is the corresponding eigenvector, then lambda * v = \" << std::endl \n",
    "            << lambda * v << std::endl;\n",
    "  std::cout << \"... and A * v = \" << std::endl \n",
    "            << A.cast<std::complex<double> >() * v << std::endl << std::endl;\n",
    "\n",
    "  Eigen::MatrixXcd D = es.eigenvalues().asDiagonal();\n",
    "  Eigen::MatrixXcd V = es.eigenvectors();\n",
    "  std::cout << \"Finally, V * D * V^(-1) = \" << std::endl \n",
    "            << V * D * V.inverse() << std::endl;\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "```\n",
    "Please compile and run it. This is a very general example and cam be simplified for specific matrices (hermitian) to improve efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3b1eb-88c9-4eba-b79c-d3c682548bcb",
   "metadata": {},
   "source": [
    "# Exercises for eigen systems\n",
    "## Eigen values Hilbert matrix\n",
    "Compute the eigen values and the condition number for the https://en.wikipedia.org/wiki/Hilbert_matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f133341-00a2-4c4e-8dad-035522fd0a6a",
   "metadata": {},
   "source": [
    "## Power method and eigen values\n",
    "Apply the https://en.wikipedia.org/wiki/Power_iteration to compute the maximum eigen value of the Vandermonde\n",
    "   matrix (or any other matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862b14a8-2c6e-4165-a591-6f357c210752",
   "metadata": {},
   "source": [
    "## Power of a matrix\n",
    "Given a matrix $A$, one can compute easily $A^k$ using diagonalization: $A^k = (PDP^{-1})^k = PDP^{-1}PDP^{-1} ... PDP^{-1} = PD^{k}P^{-1}$, where $D^k$ is just raising the eigen values to the given k power. Implement this in a function that receives an eigen matrix and a power k and returns the corresponding result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36166313-fe2e-4f6d-9ea6-e1443c80aaa4",
   "metadata": {},
   "source": [
    "## Checking stability (Heath, scientific computing)\n",
    "Compute the eigen values of the matrix\n",
    "\\begin{equation}\n",
    "A = \n",
    "\\begin{pmatrix}\n",
    "9 & 4.5 & 3\\\\\n",
    "-56 & -28 & -18\\\\\n",
    "60 & 30 & 19\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "Then do it again, but change the 19 to 18.95. What is the relative change in the eigen values magnitudes? Do the same changing it to 19.05. Can you draw any conclusion about this? can you devise a condition number to characterize this? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec5cb3c-d76f-4e39-bbb1-be45ac1cf416",
   "metadata": {},
   "source": [
    "## Markov chain (Heath, Scientific Computing)\n",
    "A Markov chain is a representation of a Markov process, which, in turns, is a random process with no memory: the current state depends only on the previous one and no more. The probability of a transition from state j to state i is given by $a_{ij}$,where $0 \\le a_{ij} \\le 1$ and $\\sum_{i=1}^n a_{ij} =1$. Let $A$ denote the matrix of transition probabilities, and let $x^{(k)}$ denote the probability that the system is  in state $i$ after transition $k$. If the initial probability distribution vector is $x^{(0)}$, then the probability distribution vector after $k$ steps is given by\n",
    "\\begin{equation}\n",
    "x^{(k)} = A x^{(k-1)} = A^k x^{(0)}.\n",
    "\\end{equation}\n",
    "\n",
    "Consider the matrix\n",
    "\\begin{equation}\n",
    "A = \n",
    "\\begin{pmatrix}\n",
    "0.8 & 0.2 & 0.1\\\\\n",
    "0.1 & 0.7 & 0.3\\\\\n",
    "0.1 & 0.1 & 0.6\\\\\n",
    "\\end{pmatrix},\n",
    "\\end{equation}\n",
    "and suposse the system is initially in state 1.\n",
    "\n",
    "- What is the probability distribution vector after three steps?\n",
    "- What is the long-term value of the probability distribution vector?\n",
    "- Does the long-term value of the probability distribution vector depend on the particular starting value ?\n",
    "- What is the value of $\\lim_{k \\to \\infty} A^k$ , and what is the rank of this matrix?\n",
    "- Explain your previous results in terms of the eigenvalues and eigenvectors of A\n",
    "- Must 1 always be an eigenvalue of the transition matrix of a Markov chain? Why?\n",
    "- A probability distribution vector x is said to be stationary if Ax = x. How can you determine such a stationary value x using the eigenvalues and eigenvectors of A?\n",
    "- How can you determine a stationary value x without knowledge of the eigenvalues and eigen- vectors of A?\n",
    "\n",
    "<!-- \n",
    "\n",
    "A singular matrix has at least a null eigen value. But what about a \"very small\" eigen value? Consider a matrix of the form\n",
    "\\begin{equation}\n",
    "A = \n",
    "\\begin{pmatrix}\n",
    "1 & -1 & -1 & -1 & -1\\\\\n",
    "0 &  1 & -1 & -1 & -1\\\\\n",
    "0 &  0 & 1 & -1 & -1\\\\\n",
    "0 &  0 & 0 & 1 & -1\\\\\n",
    "0 &  0 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "whose eigen values are 1 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e521f-50b1-40ed-be4a-522a4c2cd983",
   "metadata": {},
   "source": [
    "## TODO Matrix exponential from taylor expansion\n",
    "\n",
    "## TODO Normal modes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0997d9-def6-481f-8155-090863004734",
   "metadata": {},
   "source": [
    "# Other eigen tools\n",
    "- http://eigen.tuxfamily.org/dox/group__Sparse__chapter.html\n",
    "- http://eigen.tuxfamily.org/dox/group__Geometry__chapter.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13430830-e4b7-4222-8a32-d4243fb12aa3",
   "metadata": {},
   "source": [
    "# Eigen arrays: coefficient wise computation\n",
    "This library also implements element-wise operations and data structs,\n",
    "https://eigen.tuxfamily.org/dox/group__TutorialArrayClass.html ,\n",
    "https://eigen.tuxfamily.org/dox/group__QuickRefPage.html#title6 . There are many\n",
    "overloaded operations that you can use. Plase check the docs.\n",
    "\n",
    "This is an example of a sum, element-wise\n",
    "```c++\n",
    "#include <eigen3/Eigen/Dense>\n",
    "#include <iostream>\n",
    "\n",
    "int main()\n",
    "{\n",
    "  Eigen::ArrayXXf a(3,3);\n",
    "  Eigen::ArrayXXf b(3,3);\n",
    "  a << 1,2,3,\n",
    "       4,5,6,\n",
    "       7,8,9;\n",
    "  b << 1,2,3,\n",
    "       1,2,3,\n",
    "       1,2,3;\n",
    "\n",
    "  // Adding two arrays\n",
    "  std::cout << \"a + b = \" << std::endl << a + b << std::endl << std::endl;\n",
    "\n",
    "  // Subtracting a scalar from an array\n",
    "  std::cout << \"a - 2 = \" << std::endl << a - 2 << std::endl;\n",
    "}\n",
    "```\n",
    "\n",
    "and this an example for vector product\n",
    "```c++\n",
    "#include <eigen3/Eigen/Dense>\n",
    "#include <iostream>\n",
    "\n",
    "int main()\n",
    "{\n",
    "  Eigen::ArrayXXf a(2,2);\n",
    "  Eigen::ArrayXXf b(2,2);\n",
    "  a << 1,2,\n",
    "       3,4;\n",
    "  b << 5,6,\n",
    "       7,8;\n",
    "  std::cout << \"a * b = \" << std::endl << a * b << std::endl;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "More operations:\n",
    "```c++\n",
    "#include <eigen3/Eigen/Dense>\n",
    "#include <iostream>\n",
    "\n",
    "int main()\n",
    "{\n",
    "  Eigen::ArrayXf a = Eigen::ArrayXf::Random(5);\n",
    "  a *= 2;\n",
    "  std::cout << \"a =\" << std::endl\n",
    "            << a << std::endl;\n",
    "  std::cout << \"a.abs() =\" << std::endl\n",
    "            << a.abs() << std::endl;\n",
    "  std::cout << \"a.abs().sqrt() =\" << std::endl\n",
    "            << a.abs().sqrt() << std::endl;\n",
    "  std::cout << \"a.min(a.abs().sqrt()) =\" << std::endl\n",
    "            << a.min(a.abs().sqrt()) << std::endl;\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2160eb-52d5-497d-9569-6accb8ead534",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "## Filtering data\n",
    "Create N=1000 points between 0\n",
    "   and $2\\pi$, then compute the $\\sin$ of those numbers, and finally print only the values that fulfill that\n",
    "   $|\\sin x| \\le 0.5$. All of this without using loops.\n",
    "## MD simulation\n",
    "If you discretize time in steps of size $\\delta t$, and you have the forces on\n",
    "   a given ideal particle, you can compute the next position using the Euler\n",
    "   algorithm,\n",
    "   \\begin{align}\n",
    "    \\vec R(t+\\delta t) &= \\vec R(t) + \\delta t \\vec V(t),\\\\\n",
    "    \\vec V(t + \\delta t) &= \\vec V(t) + \\delta t \\vec F(t)/m.\\\\\n",
    "   \\end{align}\n",
    "   Use valarrays to model the vectors. Compute the trayectory of a\n",
    "   particle of mass $m=0.987$, with initial conditions $\\vec R(0) = (0, 0, 4.3),\n",
    "   V(0) = (0.123, 0.0, 0.98)$, under the influence of gravity. Plot it. Later add\n",
    "   some damping. Later add some interaction with the ground.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19db409-19fe-457f-9b23-e0e1eb7de0db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
