{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b98446-57ca-442d-a165-a23a17899bb8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25c0a4f6203f45d64be8a4db7f728eb5",
     "grade": false,
     "grade_id": "cell-268b6c129426679c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Numerical differentiation\n",
    "\n",
    "REFS:\n",
    "- Ward; Kincaid; Numerical mathematics and computing\n",
    "- Wikipedia\n",
    "\n",
    "Computing derivatives is the core of many of the numerical work done in computational physics. But it is not a trivial problem to do so with good accuracy. Numerical derivatives are the core computation in finite difference methods, optimization problems, interpolations and many more.\n",
    "\n",
    "## First approach: forward difference\n",
    "This is based on either the a Taylor expansion for a given function, or in the actual definition of the derivative (see https://en.wikipedia.org/wiki/Numerical_differentiation)\n",
    "| Definition | Graphical interpretation|\n",
    "|-|-|\n",
    "|$$f'(x) \\simeq \\frac{f(x+h) - f(x)}{h} + O(h)$$|<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Derivative.svg/460px-Derivative.svg.png\" width=500 />|\n",
    "\n",
    "\n",
    "where $h$ is a parameter that ideally goes to zero but in practice that cannot be done due to numerical accuracy. You can also define the backward derivative by just using the previous point. The error estimate can be computed using a Taylor expansion. \n",
    "\n",
    "- Visualization: <https://www.geogebra.org/m/aUjja5NV>\n",
    "- And this is actually thebase for solving differential equations!: <https://www.geogebra.org/m/NUeFjm9J>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fdcab-57af-4ef3-8ccc-b18707e38f1f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b2174d837cc4bdd17df8edde576b3eb",
     "grade": false,
     "grade_id": "cell-a7b4a2f7046d398e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## A better estimation: Central difference\n",
    "If you compute a forward ($+h$)  \n",
    "\n",
    "$$f(x+h) = f(x) + f'(x) h + f''(x) h^2/2 + f'''(x) h^3/6 + O(h^4) + O(h^5),$$\n",
    "\n",
    "and a backward ($-h$) Taylor expansion,\n",
    "\n",
    "$$f(x-h) = f(x) - f'(x) h + f''(x) h^2/2 - f'''(x) h^3/6 + O(h^4) - O(h^5),$$\n",
    "\n",
    "and then you subtract the second from the first (notice that adding then allows you to compute the second order derivative), you get\n",
    "\n",
    "$$f'(x) \\simeq \\frac{f(x+h) - f(x-h)}{2h} + O(h^2)$$\n",
    "\n",
    "which is called the central difference. The order is improved and this version is better than the simple forward difference. See: https://en.wikipedia.org/wiki/Finite_difference\n",
    "\n",
    "|Comparison among methods| Dependence on $h$|\n",
    "|-|-|\n",
    "|<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Finite_difference_method.svg/614px-Finite_difference_method.svg.png\" width=600 />|<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/AbsoluteErrorNumericalDifferentiationExample.png/600px-AbsoluteErrorNumericalDifferentiationExample.png\" width=600 />|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f975d6-c5b0-4e80-acfc-603f7e3dba03",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f0f76928b8de128f656eef797f6b68c",
     "grade": false,
     "grade_id": "cell-fd7b35611ac0a09f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "By using [Richardson extrapolation](https://en.wikipedia.org/wiki/Richardson_extrapolation), you can improve even more the central difference estimation, \n",
    "\n",
    "\\begin{equation}\n",
    "f'(x) = \\phi\\left(\\frac{h}{2}\\right) + \\frac{1}{3}\\left[\\phi\\left(\\frac{h}{2} \\right) - \\phi(h) \\right] + O(h^4),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\phi(h)$ is the derivative estimation from the central difference with a given $h$ value. **NOTE**: This form is only for the central difference, since it depends on the algorithm order. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4328831c-d092-416f-84a9-36b871e0eda5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27ca707416bc9109ff87478bac0b55e1",
     "grade": false,
     "grade_id": "cell-2efc63647d50b066",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Other important cases\n",
    "- Interpolating data and then estimating the derivative\n",
    "- Derivative of noisy data: first compute binned averages and then derive. \n",
    "- Higher order derivatives\n",
    "- N-dimensional derivatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c669d3-2fc4-4171-a21b-0ac364cc8b82",
   "metadata": {},
   "source": [
    "## Implementing forward and central derivatives\n",
    "\n",
    "Implement functions to compute both the forward and central derivatives. Explore the following case:\n",
    "Compute the derivative as a function of $x$, with fixed $h = 0.01$. Use $f(x) = \\sin(x^2)$. Compare with the exact derivative. Plot the relative difference.\n",
    "\n",
    "The prototypes might be\n",
    "```c++\n",
    "double forward_diff(double x, double h);\n",
    "double central_diff(double x, double h);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5394643b-6432-4f1d-ba9f-5344a3408c50",
   "metadata": {},
   "source": [
    "### File modularization\n",
    "\n",
    "Now try to modularize the code. Create headers and implementation files called `derivatives.h` and `derivatives.cpp`, where you are going to put declarations and implementations for both the forward and the central derivative methods. What happens now? where should the function to be derived go? We need a more generic approach. Use `using fptr = double(double)` as a function pointer, which is a construct that represents what a function returns and receives. The ideal is to use the functions as parameters\n",
    "```c++\n",
    "using fptr = double(double); // pointer(c++11) to a function which receives a double and returns a double\n",
    "double forward_diff(double x, double h, fptr fun);\n",
    "double central_diff(double x, double h, fptr fun);\n",
    "```\n",
    "\n",
    "We can even go further and try to use [C++ templates](https://hackingcpp.com/cpp/lang/templates.html), so we will have \n",
    "```c++\n",
    "template <class funptr>\n",
    "double forward_diff(double x, double h, funptr fun);\n",
    "template <class funptr>\n",
    "double central_diff(double x, double h, funptr fun);\n",
    "```\n",
    "Or even use functors or std::function. For now let's just keep this simple with `using`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47cd8e-233c-4785-83a8-ed3650ec2078",
   "metadata": {},
   "source": [
    "### Error a as function of $h$\n",
    "Now fix $ = 1.454335$, and compute (using another main function) the relative error as a function of $h \\in [10^{-16}, 10^{-15}, 10^{-14}, \\ldots, 10^{-3}, 10^{-2}, 10^{-1}]$. Plot it. Explain the differences among forward and central results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b2485-f909-466c-96d0-c08357bd681b",
   "metadata": {},
   "source": [
    "### Error as a function of both $h$ and $x$\n",
    "Is the error dependent on $x$ also? explore variations for both $x$ and $y$ and plot in a 3d picture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2884a-8c41-4941-b5f2-ca3b2d826c3f",
   "metadata": {},
   "source": [
    "## Implementing Richardson extrapolation\n",
    "Now, use the general expression for Richardson extrapolation applied to an algorithm of order $O(h^\\alpha)$, and also plot its relative differences for fixed $x$, (see https://en.wikipedia.org/wiki/Richardson_extrapolation?useskin=vector)\n",
    "\n",
    "\\begin{equation}\n",
    "I \\simeq \\dfrac{t^\\alpha I(\\frac{h}{t}) - I(h)}{t^\\alpha - 1},\n",
    "\\end{equation}\n",
    "\n",
    "where $t$ is a factor larger than 1 (tipically $t=2$), $\\alpha$ is the algorithm order, and $I$ is the value you are computing. This implies additions to both headers and implementation files, and a new main.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61869ba5-f9c7-4a5b-bcf6-c15bf4923591",
   "metadata": {},
   "source": [
    "As you can see, the Richardson implementation is very similar for both the central and the forward algorithms. Maybe there is some hope to decrease this duplication. Think about a new `using ...`Â construct. Implement it and plot all errors as a function of $h$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e9fccb-ccaf-4f39-b71d-ff4f53743cba",
   "metadata": {},
   "source": [
    "## Modularizing the files with Richardson extrapolation\n",
    "\n",
    "Until now, we have used the simple `using fptr = double(double)` for modelling a generic function to be derived. In the case of Richardson extrapolation, we have two generics:\n",
    "- the actual function to be derived\n",
    "- the actual algorithm to be used (central, forward, etc)\n",
    "Our simple approach does not work in this case. We cannot use using inside using. Also, our approach does not work with other kind of functions, like templates or lambdas. Therefore, we need to use a more generic approach. In this case, using `std::function`, which is a generalization of an object behaving like a function (you need to `#include <functional>`), we can solve this and modularize our code.\n",
    "\n",
    "Our files will be like (fill in the `// todo`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d914d530-a7fc-4450-b340-23572799748f",
   "metadata": {},
   "source": [
    "`deriv.h`: To store the declarations\n",
    "```c++\n",
    "#pragma once\n",
    "\n",
    "#include <functional>\n",
    "#include <cmath>\n",
    "\n",
    "using fptr = std::function<double(double)>;\n",
    "\n",
    "double deriv_central(fptr f, double x, double h);\n",
    "double deriv_forward(fptr f, double x, double h);\n",
    "\n",
    "// notice the fptr inside the algptr\n",
    "using algptr = std::function<double(fptr, double, double)>;\n",
    "\n",
    "double richardson(fptr f, double x, double h, algptr alg, int n); // n is the algorithm order\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff215a2-337b-4bd9-94f3-57ae05f232c3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "39e90e0bb3f86a9ac8cb336e680129fe",
     "grade": false,
     "grade_id": "cell-d7557d99f05f2163",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "`deriv.cpp`: \n",
    "```c++\n",
    "#include \"deriv.h\"\n",
    "\n",
    "double deriv_central(fptr f, double x, double h) {\n",
    "\t// Central difference formula\n",
    "\treturn (f(x + h) - f(x - h)) / (2 * h);\n",
    "}\n",
    "\n",
    "double deriv_forward(fptr f, double x, double h) {\n",
    "\t// Forward difference formula\n",
    "\treturn (f(x + h) - f(x)) / h;\n",
    "}\n",
    "\n",
    "double richardson(fptr f, double x, double h, algptr alg, int n) // n is the algorithm order\n",
    "{\n",
    "    // todo\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad69ff-f171-4c41-b3d6-3ea43b797f78",
   "metadata": {},
   "source": [
    "and our main function\n",
    "```c++\n",
    "#include <iostream>\n",
    "\n",
    "#include \"deriv.h\"\n",
    "\n",
    "double fun(double x) {\n",
    "\treturn x * x*std::sin(x);\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    std::cout.precision(16);\n",
    "    std::cout.setf(std::ios::scientific);\n",
    "\tstd::cout << deriv_forward(fun, 1.0, 0.01) << std::endl;\n",
    "\tstd::cout << deriv_central(fun, 1.0, 0.01) << std::endl;\n",
    "\tstd::cout << deriv_central([](double x){ return x*x*std::sin(x);}, 1.0, 0.01) << std::endl; // works for a lambda function\n",
    "\tstd::cout << richardson(fun, 1.0, 0.01, deriv_central, 2) << std::endl;\n",
    "\n",
    "\treturn 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bc4c86-5b74-4dd4-ad47-c6ab34c31904",
   "metadata": {},
   "source": [
    "To compile, use wither full compilation (easy but not practical with many cpp files)\n",
    "```sh\n",
    "g++ -std=c++17 deriv.cpp main_deriv.cpp\n",
    "```\n",
    "or the modularized one, which can be automated using a `Makefile`\n",
    "```sh\n",
    "g++ -std=c++17 -c deriv.cpp # Produces the object deriv.o\n",
    "g++ -std=c++17 -c main_deriv.cpp # Produces the object main_deriv.o\n",
    "g++ -std=c++17 deriv.o main_deriv.o # links both objects and produces the executable\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e67f2-c086-4f06-9aeb-bb0173c65d49",
   "metadata": {},
   "source": [
    "## Testing\n",
    "Can you of some test to write for your derivatives? Implement some tests in another main file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8373571c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
